{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/software/Anaconda3-5.0.1-el7-x86_64/envs/DL_GPU_cuda_9.0/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import time\n",
    "\n",
    "# Convert labels to one-hot vectors\n",
    "\n",
    "# Convert classes to indicator vectors\n",
    "def one_hot(values,n_values=10):\n",
    "    n_v = np.maximum(n_values,np.max(values) + 1)\n",
    "    oh=np.eye(n_v)[values]\n",
    "    return oh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Mnist data and split into train validation and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mnist():\n",
    "\n",
    "    data=np.float64(np.load('/project/cmsc25025/mnist/MNIST.npy'))\n",
    "    print(data.shape)\n",
    "    labels=np.float32(np.load('/project/cmsc25025/mnist/MNIST_labels.npy'))\n",
    "    print(data.shape)\n",
    "    data=np.float32(data)/255.\n",
    "    train_dat=data[0:50000]\n",
    "    train_labels=one_hot(np.int32(labels[0:50000]))\n",
    "    val_dat=data[50000:60000]\n",
    "    val_labels=one_hot(np.int32(labels[50000:60000]))\n",
    "    test_dat=data[60000:70000]\n",
    "    test_labels=one_hot(np.int32(labels[60000:70000]))\n",
    "    \n",
    "    return (train_dat, train_labels), (val_dat, val_labels), (test_dat, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get CIFAR10 data and split into train validation and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cifar():\n",
    "    tr=np.float32(np.load('/project/cmsc25025/mnist/CIFAR_10.npy'))\n",
    "    tr_lb=np.int32(np.load('/project/cmsc25025/mnist/CIFAR_labels.npy'))\n",
    "    tr=tr.reshape((-1,np.prod(np.array(tr.shape)[1:4])))\n",
    "    train_data=tr[0:45000]/255.\n",
    "    train_labels=one_hot(tr_lb[0:45000])\n",
    "    val_data=tr[45000:]/255.\n",
    "    val_labels=one_hot(tr_lb[45000:])\n",
    "    test_data=np.float32(np.load('/project/cmsc25025/mnist/CIFAR_10_test.npy'))\n",
    "    test_data=test_data.reshape((-1,np.prod(np.array(test_data.shape)[1:4])))\n",
    "    test_data=test_data/255.\n",
    "    test_labels=one_hot(np.int32(np.load('/project/cmsc25025/mnist/CIFAR_labels_test.npy')))\n",
    "    return (train_data, train_labels), (val_data, val_labels), (test_data, test_labels)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get transformed Mnist data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mnist_trans():\n",
    "    test_trans_dat=np.float32(np.load('/project/cmsc25025/mnist/MNIST_TEST_TRANS.npy'))\n",
    "    test_labels=one_hot(np.int32(np.float32(np.load('/project/cmsc25025/mnist/MNIST_labels.npy'))))\n",
    "    return (test_trans_dat, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolution layer with relu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_relu_layer(input,filter_size=[3,3],num_features=[1]):\n",
    "\n",
    "    # Get number of input features from input and add to shape of new layer\n",
    "    shape=filter_size+[input.get_shape().as_list()[-1],num_features]\n",
    "    W = tf.get_variable('W',shape=shape)/np.sqrt(3.) # Default initialization is Glorot (the one explained in the slides)\n",
    "    #b = tf.get_variable('b',shape=[num_features],initializer=tf.zeros_initializer) \n",
    "    conv = tf.nn.conv2d(input, W, strides=[1, 1, 1, 1], padding='SAME')\n",
    "    relu = tf.nn.relu(conv)\n",
    "    return(relu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fully connected layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fully_connected_layer(input,num_features):\n",
    "    # Make sure input is flattened.\n",
    "    flat_dim=np.int32(np.array(input.get_shape().as_list())[1:].prod())\n",
    "    input_flattened = tf.reshape(input, shape=[-1,flat_dim])\n",
    "    shape=[flat_dim,num_features]\n",
    "    W_fc = tf.get_variable('W',shape=shape)/np.sqrt(3.)\n",
    "    #b_fc = tf.get_variable('b',shape=[num_features],initializer=tf.zeros_initializer)\n",
    "    fc = tf.matmul(input_flattened, W_fc) #+ b_fc\n",
    "    return(fc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The network. Original architecture (no biases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tf.reset_default_graph()\n",
    "\n",
    "def create_network(x_image,y_,keep_prob):\n",
    "    pool_ksize=[1,2,2,1]\n",
    "    pool_strides=[1,2,2,1]\n",
    "    # The network:\n",
    "    with tf.variable_scope(\"conv1\"):\n",
    "            # Variables created here will be named \"conv1/weights\", \"conv1/biases\".\n",
    "            relu1 = conv_relu_layer(x_image, filter_size=[5, 5],num_features=32)\n",
    "            pool1 = tf.nn.max_pool(relu1, ksize=pool_ksize, strides=pool_strides, padding='SAME')\n",
    "    with tf.variable_scope(\"conv2\"):\n",
    "            # Variables created here will be named \"conv1/weights\", \"conv1/biases\".\n",
    "            relu2 = conv_relu_layer(pool1, filter_size=[5, 5],num_features=64)\n",
    "            pool2 = tf.nn.max_pool(relu2, ksize=pool_ksize, strides=pool_strides, padding='SAME')\n",
    "    with tf.variable_scope('dropout2'):\n",
    "            drop2=tf.nn.dropout(pool2,keep_prob)\n",
    "    with tf.variable_scope(\"fc1\"):\n",
    "            fc1 = fully_connected_layer(drop2, num_features=256)\n",
    "            fc1r=tf.nn.relu(fc1)\n",
    "   \n",
    "    with tf.variable_scope(\"fc2\"):\n",
    "            fc2 = fully_connected_layer(fc1r, num_features=10)\n",
    "\n",
    "    # Names (OUT,LOSS, ACC) below added to make it easier to use this tensor when restoring model\n",
    "    fc2 = tf.identity(fc2, name=\"OUT\")\n",
    "    # The loss computation\n",
    "    with tf.variable_scope('cross_entropy_loss'):\n",
    "        cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y_, logits=fc2),name=\"LOSS\")\n",
    "\n",
    "    # Accuracy computation\n",
    "    with tf.variable_scope('helpers'):\n",
    "        correct_prediction = tf.equal(tf.argmax(fc2, 1), tf.argmax(y_, 1))\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32),name=\"ACC\")\n",
    "    # We return the final functions (they contain all the information about the graph of the network)\n",
    "    return cross_entropy, accuracy, fc2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Half the number of features - half as many filters in conv1, half as many units in fc1, conv2 remains the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tf.reset_default_graph()\n",
    "\n",
    "def create_network_1(x_image,y_, keep_prob):\n",
    "    pool_ksize=[1,2,2,1]\n",
    "    pool_strides=[1,2,2,1]\n",
    "    # The network:\n",
    "    with tf.variable_scope(\"conv1\"):\n",
    "            # Variables created here will be named \"conv1/weights\", \"conv1/biases\".\n",
    "            relu1 = conv_relu_layer(x_image, filter_size=[5, 5],num_features=16)\n",
    "            pool1 = tf.nn.max_pool(relu1, ksize=pool_ksize, strides=pool_strides, padding='SAME')\n",
    "    with tf.variable_scope(\"conv2\"):\n",
    "            # Variables created here will be named \"conv1/weights\", \"conv1/biases\".\n",
    "            relu2 = conv_relu_layer(pool1, filter_size=[5, 5],num_features=64)\n",
    "            pool2 = tf.nn.max_pool(relu2, ksize=pool_ksize, strides=pool_strides, padding='SAME')\n",
    "    with tf.variable_scope('dropout2'):\n",
    "            drop2=tf.nn.dropout(pool2,keep_prob)\n",
    "    with tf.variable_scope(\"fc1\"):\n",
    "            fc1 = fully_connected_layer(drop2, num_features=128)\n",
    "            fc1r=tf.nn.relu(fc1)\n",
    "   \n",
    "    with tf.variable_scope(\"fc2\"):\n",
    "            fc2 = fully_connected_layer(fc1r, num_features=10)\n",
    "\n",
    "    # Names (OUT,LOSS, ACC) below added to make it easier to use this tensor when restoring model\n",
    "    fc2 = tf.identity(fc2, name=\"OUT\")\n",
    "    # The loss computation\n",
    "    with tf.variable_scope('cross_entropy_loss'):\n",
    "        cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y_, logits=fc2),name=\"LOSS\")\n",
    "\n",
    "    # Accuracy computation\n",
    "    with tf.variable_scope('helpers'):\n",
    "        correct_prediction = tf.equal(tf.argmax(fc2, 1), tf.argmax(y_, 1))\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32),name=\"ACC\")\n",
    "    # We return the final functions (they contain all the information about the graph of the network)\n",
    "    return cross_entropy, accuracy, fc2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Twice the number of features - twice as many filters in conv1, twice as many units in fc1, conv2 remains the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tf.reset_default_graph()\n",
    "\n",
    "def create_network_2(x_image,y_, keep_prob):\n",
    "    pool_ksize=[1,2,2,1]\n",
    "    pool_strides=[1,2,2,1]\n",
    "    # The network:\n",
    "    with tf.variable_scope(\"conv1\"):\n",
    "            # Variables created here will be named \"conv1/weights\", \"conv1/biases\".\n",
    "            relu1 = conv_relu_layer(x_image, filter_size=[5, 5],num_features=64)\n",
    "            pool1 = tf.nn.max_pool(relu1, ksize=pool_ksize, strides=pool_strides, padding='SAME')\n",
    "    with tf.variable_scope(\"conv2\"):\n",
    "            # Variables created here will be named \"conv1/weights\", \"conv1/biases\".\n",
    "            relu2 = conv_relu_layer(pool1, filter_size=[5, 5],num_features=64)\n",
    "            pool2 = tf.nn.max_pool(relu2, ksize=pool_ksize, strides=pool_strides, padding='SAME')\n",
    "    with tf.variable_scope('dropout2'):\n",
    "            drop2=tf.nn.dropout(pool2,keep_prob)\n",
    "    with tf.variable_scope(\"fc1\"):\n",
    "            fc1 = fully_connected_layer(drop2, num_features=512)\n",
    "            fc1r=tf.nn.relu(fc1)\n",
    "   \n",
    "    with tf.variable_scope(\"fc2\"):\n",
    "            fc2 = fully_connected_layer(fc1r, num_features=10)\n",
    "\n",
    "    # Names (OUT,LOSS, ACC) below added to make it easier to use this tensor when restoring model\n",
    "    fc2 = tf.identity(fc2, name=\"OUT\")\n",
    "    # The loss computation\n",
    "    with tf.variable_scope('cross_entropy_loss'):\n",
    "        cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y_, logits=fc2),name=\"LOSS\")\n",
    "\n",
    "    # Accuracy computation\n",
    "    with tf.variable_scope('helpers'):\n",
    "        correct_prediction = tf.equal(tf.argmax(fc2, 1), tf.argmax(y_, 1))\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32),name=\"ACC\")\n",
    "    # We return the final functions (they contain all the information about the graph of the network)\n",
    "    return cross_entropy, accuracy, fc2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For each conv layer in previous architecture, 2 consecutive conv layers with smaller filters (3x3). Same numbers of filters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tf.reset_default_graph()\n",
    "\n",
    "def create_network_3(x_image,y_, keep_prob):\n",
    "    pool_ksize=[1,2,2,1]\n",
    "    pool_strides=[1,2,2,1]\n",
    "    # The network:\n",
    "    with tf.variable_scope(\"conv1\"):\n",
    "            # Variables created here will be named \"conv1/weights\", \"conv1/biases\".\n",
    "            relu1 = conv_relu_layer(x_image, filter_size=[3, 3],num_features=32)\n",
    "    with tf.variable_scope(\"conv1a\"):\n",
    "            relu1a = conv_relu_layer(relu1, filter_size=[3, 3],num_features=32)\n",
    "            pool1 = tf.nn.max_pool(relu1a, ksize=pool_ksize, strides=pool_strides, padding='SAME')\n",
    "    with tf.variable_scope(\"conv2\"):\n",
    "            # Variables created here will be named \"conv1/weights\", \"conv1/biases\".\n",
    "            relu2 = conv_relu_layer(pool1, filter_size=[3, 3],num_features=64)\n",
    "    with tf.variable_scope(\"conv2a\"):\n",
    "            relu2a = conv_relu_layer(relu2, filter_size=[3, 3],num_features=64)\n",
    "            pool2 = tf.nn.max_pool(relu2a, ksize=pool_ksize, strides=pool_strides, padding='SAME')\n",
    "    with tf.variable_scope('dropout2'):\n",
    "            drop2=tf.nn.dropout(pool2,keep_prob)\n",
    "    with tf.variable_scope(\"fc1\"):\n",
    "            fc1 = fully_connected_layer(drop2, num_features=256)\n",
    "            fc1r=tf.nn.relu(fc1)\n",
    "   \n",
    "    with tf.variable_scope(\"fc2\"):\n",
    "            fc2 = fully_connected_layer(fc1r, num_features=10)\n",
    "\n",
    "    # Names (OUT,LOSS, ACC) below added to make it easier to use this tensor when restoring model\n",
    "    fc2 = tf.identity(fc2, name=\"OUT\")\n",
    "    # The loss computation\n",
    "    with tf.variable_scope('cross_entropy_loss'):\n",
    "        cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y_, logits=fc2),name=\"LOSS\")\n",
    "\n",
    "    # Accuracy computation\n",
    "    with tf.variable_scope('helpers'):\n",
    "        correct_prediction = tf.equal(tf.argmax(fc2, 1), tf.argmax(y_, 1))\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32),name=\"ACC\")\n",
    "    # We return the final functions (they contain all the information about the graph of the network)\n",
    "    return cross_entropy, accuracy, fc2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get loss and accuracy on a data set with output from final layer fc2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import logsumexp\n",
    "\n",
    "def get_stats(data,labels,fc2,x,y_):\n",
    "    t1=time.time()\n",
    "    lo=0.\n",
    "    acc=0.\n",
    "    delta=1000\n",
    "    rr=np.arange(0,data.shape[0],delta)\n",
    "    for i in rr:\n",
    "        fc2_out=fc2.eval(feed_dict={x: data[i:i+delta], y_:labels[i:i+delta]})\n",
    "        log_sf=logsumexp(fc2_out,axis=1).reshape((fc2_out.shape[0],1))-fc2_out\n",
    "        lo+=np.mean(np.sum(labels[i:i+delta]*log_sf, axis=1))\n",
    "        acc += np.mean(np.equal(np.argmax(fc2_out, axis=1),np.argmax(labels[i:i+delta], axis=1)))\n",
    "    acc=acc/np.float32(len(rr))\n",
    "    lo=lo/np.float32(len(rr))\n",
    "    #print('get stats time',time.time()-t1)\n",
    "    # We return the final functions (they contain all the information about the graph of the network)\n",
    "    return lo, acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run one epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Run the iterations of one epoch\n",
    "def run_epoch(train,val,ii,batch_size,train_step_new,step_size,keep_prob,x,y_,lr_,keep_prob_):\n",
    "        t1=time.time()\n",
    "        # Randomly shuffle the training data\n",
    "        np.random.shuffle(ii)\n",
    "        tr=train[0][ii]\n",
    "        y=train[1][ii]\n",
    "        lo=0.\n",
    "        acc=0.\n",
    "        # Run disjoint batches on shuffled data\n",
    "        for j in np.arange(0,len(y),batch_size):\n",
    "            batch=(tr[j:j+batch_size],y[j:j+batch_size])\n",
    "            train_step_new.run(feed_dict={x: batch[0], y_: batch[1], lr_: step_size,keep_prob_:keep_prob})\n",
    "        print('Epoch time',time.time()-t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(data_set):\n",
    "    if (data_set==\"cifar\"):\n",
    "        return(get_cifar())\n",
    "    elif (data_set==\"mnist\"):\n",
    "        return(get_mnist())\n",
    "    elif (data_set==\"mnist_transform\"):\n",
    "        return(get_mnist_trans())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the training on network `create_network'. Save the model and test at the endÂ¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the training\n",
    "def run_net(create_network=create_network,data_set=\"mnist\",draw=True):\n",
    "    \n",
    "    batch_size=500\n",
    "    step_size=.001\n",
    "    num_epochs=20\n",
    "    num_train=45000\n",
    "    minimizer=\"Adam\"\n",
    "    model_name=\"model\"\n",
    "    keep_prob=1.\n",
    "    dim=28\n",
    "    nchannels=1\n",
    "\n",
    "    create=create_network\n",
    "    stats=get_stats\n",
    "\n",
    "    if (data_set==\"cifar\"):\n",
    "        dim=32\n",
    "        nchannels=3\n",
    "\n",
    "\n",
    "    tf.reset_default_graph()\n",
    "\n",
    "    x = tf.placeholder(tf.float32, shape=[None, dim*dim*nchannels],name=\"x\")\n",
    "    x_image = tf.reshape(x, [-1, dim, dim, nchannels])\n",
    "    # Dimensions of x_image: [Batch size, Column size, Row size, Number of incoming channels]\n",
    "    # The number of incoming channels, for example, will be 3 if the image is color: RGB (red, green, blue)\n",
    "    # We will slide filter over this 2d picture with conv2d function.\n",
    "    y_ = tf.placeholder(tf.float32, shape=[None,10],name=\"y\")\n",
    "    # Allows you to control the time step during the iterations\n",
    "    lr_ = tf.placeholder(tf.float32, shape=[],name=\"learning_rate\")\n",
    "    keep_prob_=tf.placeholder(tf.float32, shape=[],name=\"keep_prob\")\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "            train,val,test=get_data(data_set=data_set)\n",
    "            # Create the network architecture with the above placeholdes as the inputs.\n",
    "            cross_entropy, accuracy, fc2 =create(x_image,y_,keep_prob)\n",
    "\n",
    "            # Define the miminization method\n",
    "            if (minimizer==\"Adam\"):\n",
    "                train_step=tf.train.AdamOptimizer(learning_rate=lr_).minimize(cross_entropy)\n",
    "            elif (minimizer==\"SGD\"):\n",
    "                train_step = tf.train.GradientDescentOptimizer(learning_rate=lr_).minimize(cross_entropy)\n",
    "            # Initialize variables\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "            # Show trainable variables\n",
    "            num_pars=0\n",
    "            for v in tf.trainable_variables():\n",
    "                num_pars+=np.prod(np.array(v.get_shape().as_list()))\n",
    "                print(v.name,v.get_shape().as_list(),np.std(v.eval()))\n",
    "            print('Total params',num_pars)\n",
    "            ii=np.arange(0,num_train,1) #len(train_data),1)\n",
    "            # Run epochs\n",
    "            for i in range(num_epochs):  # number of epochs\n",
    "                # Place holders need to passed along to the function they are no longer global.\n",
    "                run_epoch(train,val,ii,batch_size,train_step,step_size,keep_prob,x,y_,lr_,keep_prob_)\n",
    "                if (np.mod(i,1)==0):\n",
    "                    # Same here with placeholders.\n",
    "                    lo,ac = stats(train[0][0:num_train],train[1][0:num_train],fc2,x,y_)\n",
    "                    print('Epoch',i,'Train loss, accuracy',lo,ac)\n",
    "                    vlo,vac = stats(val[0],val[1],fc2,x,y_)\n",
    "                    print('EPoch',i,'Validation loss, accuracy',vlo,vac)\n",
    "                    # Test set accuracy\n",
    "\n",
    "            print('test accuracy %g' % accuracy.eval(feed_dict={x: test[0], y_:test[1]}))\n",
    "            v=tf.trainable_variables()[0]\n",
    "            W=v.eval()\n",
    "            \n",
    "            if (draw):\n",
    "                if (data_set==\"mnist\"):\n",
    "                    plt.figure(figsize=(16,8))\n",
    "                    for i in range(W.shape[3]):\n",
    "                        im=W[:,:,:,i].reshape(5,5)\n",
    "                    im=(im-np.min(im))/(np.max(im)-np.min(im))\n",
    "                    plt.subplot(4,8,i+1)\n",
    "                    plt.imshow(im,cmap=\"gray\")\n",
    "                    plt.axis('off')\n",
    "                elif (data_set==\"cifar\"):\n",
    "                    plt.figure(figsize=(6,64))\n",
    "                    t=1\n",
    "                    for i in range(W.shape[3]):\n",
    "                        im=W[:,:,:,i].reshape(5,5,3)\n",
    "                        for c in range(3):\n",
    "                            plt.subplot(32,3,t)\n",
    "                            t+=1\n",
    "                            plt.imshow(im[:,:,c],cmap=\"gray\")\n",
    "                            plt.axis('off')\n",
    "            # Save model\n",
    "            tf.add_to_collection(\"optimizer\", train_step)\n",
    "            saver = tf.train.Saver()\n",
    "            save_path = saver.save(sess, \"tmp/\"+model_name)\n",
    "            print(\"Model saved in path: %s\" % save_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running MNIST with basic architecture to show lower level filters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(70000, 784)\n",
      "(70000, 784)\n",
      "conv1/W:0 [5, 5, 1, 32] 0.04976173\n",
      "conv2/W:0 [5, 5, 32, 64] 0.028829087\n",
      "fc1/W:0 [3136, 256] 0.024281139\n",
      "fc2/W:0 [256, 10] 0.08723366\n",
      "Total params 857376\n",
      "Epoch time 3.070348024368286\n",
      "Epoch 0 Train loss, accuracy 0.1870660586190224 0.9427000000000002\n",
      "EPoch 0 Validation loss, accuracy 0.17463374711275104 0.9475999999999999\n",
      "Epoch time 2.7948474884033203\n",
      "Epoch 1 Train loss, accuracy 0.09643897057771682 0.9705599999999999\n",
      "EPoch 1 Validation loss, accuracy 0.08699187672138213 0.9738999999999999\n",
      "Epoch time 2.798830509185791\n",
      "Epoch 2 Train loss, accuracy 0.07136963263034819 0.9777800000000001\n",
      "EPoch 2 Validation loss, accuracy 0.0644684206843376 0.9773\n",
      "Epoch time 4.141128063201904\n",
      "Epoch 3 Train loss, accuracy 0.056269887034893024 0.9829399999999996\n",
      "EPoch 3 Validation loss, accuracy 0.051214538979530336 0.9838999999999999\n",
      "Epoch time 2.8094210624694824\n",
      "Epoch 4 Train loss, accuracy 0.042700421957969664 0.9870999999999998\n",
      "EPoch 4 Validation loss, accuracy 0.04147955963611603 0.986\n",
      "Epoch time 2.81040620803833\n",
      "Epoch 5 Train loss, accuracy 0.03654530140876769 0.9885599999999997\n",
      "EPoch 5 Validation loss, accuracy 0.03653834977149963 0.9883000000000001\n",
      "Epoch time 2.8134639263153076\n",
      "Epoch 6 Train loss, accuracy 0.029764957110881812 0.991\n",
      "EPoch 6 Validation loss, accuracy 0.0330403247833252 0.9894999999999999\n",
      "Epoch time 4.127838134765625\n",
      "Epoch 7 Train loss, accuracy 0.032008361377716066 0.9895399999999998\n",
      "EPoch 7 Validation loss, accuracy 0.03726953945159913 0.9875999999999998\n",
      "Epoch time 2.8137972354888916\n",
      "Epoch 8 Train loss, accuracy 0.027806601314544682 0.9915599999999999\n",
      "EPoch 8 Validation loss, accuracy 0.03802175126075745 0.9865999999999999\n",
      "Epoch time 2.8185009956359863\n",
      "Epoch 9 Train loss, accuracy 0.0209304099559784 0.9935199999999998\n",
      "EPoch 9 Validation loss, accuracy 0.03284157755374909 0.9888000000000001\n",
      "Epoch time 2.818159818649292\n",
      "Epoch 10 Train loss, accuracy 0.016892666521072387 0.9951199999999999\n",
      "EPoch 10 Validation loss, accuracy 0.025903004384040834 0.9911999999999999\n",
      "Epoch time 2.820566177368164\n",
      "Epoch 11 Train loss, accuracy 0.01442963620185852 0.9958599999999997\n",
      "EPoch 11 Validation loss, accuracy 0.02808097932338715 0.991\n",
      "Epoch time 2.8188655376434326\n",
      "Epoch 12 Train loss, accuracy 0.013378543357849122 0.9960000000000001\n",
      "EPoch 12 Validation loss, accuracy 0.02811592054367066 0.9904999999999999\n",
      "Epoch time 2.8206889629364014\n",
      "Epoch 13 Train loss, accuracy 0.012692067012786867 0.9962799999999996\n",
      "EPoch 13 Validation loss, accuracy 0.029031134104728695 0.9907999999999999\n",
      "Epoch time 2.8213462829589844\n",
      "Epoch 14 Train loss, accuracy 0.0124546266078949 0.9962800000000002\n",
      "EPoch 14 Validation loss, accuracy 0.02877348232269287 0.9904999999999999\n",
      "Epoch time 2.8252179622650146\n",
      "Epoch 15 Train loss, accuracy 0.010056890449523927 0.9970199999999997\n",
      "EPoch 15 Validation loss, accuracy 0.029679841399192813 0.9899999999999999\n",
      "Epoch time 2.8185410499572754\n",
      "Epoch 16 Train loss, accuracy 0.007333383531570433 0.99788\n",
      "EPoch 16 Validation loss, accuracy 0.028069252967834475 0.9908999999999999\n",
      "Epoch time 2.8147008419036865\n",
      "Epoch 17 Train loss, accuracy 0.007227098836898801 0.99812\n",
      "EPoch 17 Validation loss, accuracy 0.030845220422744752 0.9907\n",
      "Epoch time 2.8205511569976807\n",
      "Epoch 18 Train loss, accuracy 0.00636016562461853 0.99824\n",
      "EPoch 18 Validation loss, accuracy 0.029060253548622128 0.9911999999999999\n",
      "Epoch time 2.8171350955963135\n",
      "Epoch 19 Train loss, accuracy 0.004569990553855896 0.9988000000000001\n",
      "EPoch 19 Validation loss, accuracy 0.027537028288841248 0.9919\n",
      "test accuracy 0.9906\n",
      "(5, 5, 1, 32)\n",
      "Model saved in path: tmp/model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x576 with 32 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run_net(create_network,data_set=\"mnist\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run base network on CIFAR10 images. At the end show the Red, green and blue channels of all 32 filters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1/W:0 [5, 5, 3, 32] 0.047248516\n",
      "conv2/W:0 [5, 5, 32, 64] 0.028832799\n",
      "fc1/W:0 [4096, 256] 0.021444997\n",
      "fc2/W:0 [256, 10] 0.08723276\n",
      "Total params 1104736\n",
      "Epoch time 3.508297920227051\n",
      "Epoch 0 Train loss, accuracy 1.6459719382656943 0.41248888888888907\n",
      "EPoch 0 Validation loss, accuracy 1.6435893629312517 0.41179999999999994\n",
      "Epoch time 3.2815494537353516\n",
      "Epoch 1 Train loss, accuracy 1.4353472941478094 0.4955333333333333\n",
      "EPoch 1 Validation loss, accuracy 1.4376005763292314 0.492\n",
      "Epoch time 3.2784512042999268\n",
      "Epoch 2 Train loss, accuracy 1.3417468444426854 0.5268888888888891\n",
      "EPoch 2 Validation loss, accuracy 1.3512494900941847 0.522\n",
      "Epoch time 3.2828285694122314\n",
      "Epoch 3 Train loss, accuracy 1.2872168014473386 0.5410444444444445\n",
      "EPoch 3 Validation loss, accuracy 1.288596516251564 0.539\n",
      "Epoch time 3.2844161987304688\n",
      "Epoch 4 Train loss, accuracy 1.2122804423146776 0.5772444444444444\n",
      "EPoch 4 Validation loss, accuracy 1.232036431002617 0.5708\n",
      "Epoch time 3.3178956508636475\n",
      "Epoch 5 Train loss, accuracy 1.160496363200082 0.589111111111111\n",
      "EPoch 5 Validation loss, accuracy 1.1831291277647018 0.588\n",
      "Epoch time 3.284472942352295\n",
      "Epoch 6 Train loss, accuracy 1.0772229216284224 0.6238888888888888\n",
      "EPoch 6 Validation loss, accuracy 1.1001584123373032 0.6226\n",
      "Epoch time 3.2877182960510254\n",
      "Epoch 7 Train loss, accuracy 1.0546085069020594 0.633\n",
      "EPoch 7 Validation loss, accuracy 1.0890663659811017 0.6268\n",
      "Epoch time 3.2916994094848633\n",
      "Epoch 8 Train loss, accuracy 1.02950414908727 0.6413999999999999\n",
      "EPoch 8 Validation loss, accuracy 1.0706151311397551 0.6245999999999999\n",
      "Epoch time 3.286548376083374\n",
      "Epoch 9 Train loss, accuracy 0.969163468352954 0.6655111111111112\n",
      "EPoch 9 Validation loss, accuracy 1.0257597674131393 0.6456\n",
      "Epoch time 3.287400960922241\n",
      "Epoch 10 Train loss, accuracy 0.9262977993461817 0.6819777777777777\n",
      "EPoch 10 Validation loss, accuracy 0.988658001446724 0.6564\n",
      "Epoch time 3.295517683029175\n",
      "Epoch 11 Train loss, accuracy 0.9173149634308283 0.6832444444444443\n",
      "EPoch 11 Validation loss, accuracy 0.9922072204113007 0.6584000000000001\n",
      "Epoch time 3.2981784343719482\n",
      "Epoch 12 Train loss, accuracy 0.9106363799545499 0.685133333333333\n",
      "EPoch 12 Validation loss, accuracy 0.9942467394351959 0.659\n",
      "Epoch time 3.2907145023345947\n",
      "Epoch 13 Train loss, accuracy 0.8499572493553161 0.7105555555555556\n",
      "EPoch 13 Validation loss, accuracy 0.9517926474094391 0.6718\n",
      "Epoch time 3.312570095062256\n",
      "Epoch 14 Train loss, accuracy 0.8204641893267631 0.7196444444444443\n",
      "EPoch 14 Validation loss, accuracy 0.9291858076572417 0.6811999999999999\n",
      "Epoch time 3.2943482398986816\n",
      "Epoch 15 Train loss, accuracy 0.7995574693375165 0.7258666666666665\n",
      "EPoch 15 Validation loss, accuracy 0.9249820993900298 0.6826000000000001\n",
      "Epoch time 3.3049890995025635\n",
      "Epoch 16 Train loss, accuracy 0.7839175206687716 0.7323111111111111\n",
      "EPoch 16 Validation loss, accuracy 0.922318086862564 0.683\n",
      "Epoch time 3.293820381164551\n",
      "Epoch 17 Train loss, accuracy 0.7323125784715016 0.7520888888888888\n",
      "EPoch 17 Validation loss, accuracy 0.8908703324317931 0.696\n",
      "Epoch time 3.2983710765838623\n",
      "Epoch 18 Train loss, accuracy 0.7159578842189577 0.7568444444444444\n",
      "EPoch 18 Validation loss, accuracy 0.8952281964898109 0.6998\n",
      "Epoch time 3.293565034866333\n",
      "Epoch 19 Train loss, accuracy 0.710040009168784 0.7553111111111112\n",
      "EPoch 19 Validation loss, accuracy 0.906171246099472 0.6985999999999999\n",
      "test accuracy 0.6707\n",
      "(5, 5, 3, 32)\n",
      "Model saved in path: tmp/model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x4608 with 96 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run_net(create_network,data_set=\"cifar\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run half the number of parameters on CIFAR10 images. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-9-8d56695b3d4f>:28: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See @{tf.nn.softmax_cross_entropy_with_logits_v2}.\n",
      "\n",
      "conv1/W:0 [5, 5, 3, 16] 0.06596251\n",
      "conv2/W:0 [5, 5, 16, 64] 0.031592615\n",
      "fc1/W:0 [4096, 128] 0.021771511\n",
      "fc2/W:0 [128, 10] 0.11973144\n",
      "Total params 552368\n",
      "Epoch time 3.759420394897461\n",
      "Epoch 0 Train loss, accuracy 1.676028780118624 0.40853333333333325\n",
      "EPoch 0 Validation loss, accuracy 1.678031587743759 0.4006\n",
      "Epoch time 2.6100049018859863\n",
      "Epoch 1 Train loss, accuracy 1.5195959856642616 0.45655555555555566\n",
      "EPoch 1 Validation loss, accuracy 1.5281542422533037 0.453\n",
      "Epoch time 2.6661999225616455\n",
      "Epoch 2 Train loss, accuracy 1.4017727389600543 0.5079777777777779\n",
      "EPoch 2 Validation loss, accuracy 1.4023621407747267 0.506\n",
      "Epoch time 2.5859899520874023\n",
      "Epoch 3 Train loss, accuracy 1.3321895849333871 0.5307555555555558\n",
      "EPoch 3 Validation loss, accuracy 1.3329665858268738 0.5298\n",
      "Epoch time 2.6222598552703857\n",
      "Epoch 4 Train loss, accuracy 1.2732812496927053 0.5507333333333334\n",
      "EPoch 4 Validation loss, accuracy 1.2857732926368715 0.5466000000000001\n",
      "Epoch time 2.5589423179626465\n",
      "Epoch 5 Train loss, accuracy 1.2200366429408391 0.5686888888888888\n",
      "EPoch 5 Validation loss, accuracy 1.234862096309662 0.5652\n",
      "Epoch time 2.565178632736206\n",
      "Epoch 6 Train loss, accuracy 1.1578018688281377 0.5969777777777776\n",
      "EPoch 6 Validation loss, accuracy 1.1759865789413453 0.5952\n",
      "Epoch time 2.559359550476074\n",
      "Epoch 7 Train loss, accuracy 1.1320041014035542 0.6078444444444444\n",
      "EPoch 7 Validation loss, accuracy 1.1515856195926666 0.6012000000000001\n",
      "Epoch time 2.56951642036438\n",
      "Epoch 8 Train loss, accuracy 1.1013810457309086 0.6153777777777778\n",
      "EPoch 8 Validation loss, accuracy 1.131460692644119 0.6062\n",
      "Epoch time 2.575244903564453\n",
      "Epoch 9 Train loss, accuracy 1.075655039948887 0.6243777777777777\n",
      "EPoch 9 Validation loss, accuracy 1.1098513316154481 0.6154\n",
      "Epoch time 2.568272590637207\n",
      "Epoch 10 Train loss, accuracy 1.0193915257083046 0.6439999999999999\n",
      "EPoch 10 Validation loss, accuracy 1.0654173241853715 0.632\n",
      "Epoch time 2.567533016204834\n",
      "Epoch 11 Train loss, accuracy 0.9958670594983628 0.6538444444444445\n",
      "EPoch 11 Validation loss, accuracy 1.0457298370838166 0.6376000000000001\n",
      "Epoch time 2.5718321800231934\n",
      "Epoch 12 Train loss, accuracy 0.9805772264242173 0.6605555555555556\n",
      "EPoch 12 Validation loss, accuracy 1.0392321234941482 0.6397999999999999\n",
      "Epoch time 2.573500394821167\n",
      "Epoch 13 Train loss, accuracy 0.9378848955869677 0.6749111111111112\n",
      "EPoch 13 Validation loss, accuracy 1.0030559581518173 0.6558\n",
      "Epoch time 2.5709826946258545\n",
      "Epoch 14 Train loss, accuracy 0.9126465453783672 0.6846222222222222\n",
      "EPoch 14 Validation loss, accuracy 0.9913998449087144 0.662\n",
      "Epoch time 2.576730251312256\n",
      "Epoch 15 Train loss, accuracy 0.8983963656875825 0.6890444444444443\n",
      "EPoch 15 Validation loss, accuracy 0.9815766519784928 0.6644\n",
      "Epoch time 2.6343636512756348\n",
      "Epoch 16 Train loss, accuracy 0.910943611682786 0.6852444444444445\n",
      "EPoch 16 Validation loss, accuracy 1.0092829748630525 0.6548\n",
      "Epoch time 2.6006815433502197\n",
      "Epoch 17 Train loss, accuracy 0.8605238129602537 0.7035999999999999\n",
      "EPoch 17 Validation loss, accuracy 0.9575369706869126 0.6774\n",
      "Epoch time 2.5807888507843018\n",
      "Epoch 18 Train loss, accuracy 0.84120839461618 0.712022222222222\n",
      "EPoch 18 Validation loss, accuracy 0.952904067826271 0.6788\n",
      "Epoch time 2.5953292846679688\n",
      "Epoch 19 Train loss, accuracy 0.8487606105566023 0.7054888888888887\n",
      "EPoch 19 Validation loss, accuracy 0.9643117067813873 0.67\n",
      "test accuracy 0.6581\n",
      "Model saved in path: tmp/model\n"
     ]
    }
   ],
   "source": [
    "run_net(create_network_1,data_set=\"cifar\",draw=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run twice the number of parameters on CIFAR10 images. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1/W:0 [5, 5, 3, 64] 0.0346007\n",
      "conv2/W:0 [5, 5, 64, 64] 0.02499464\n",
      "fc1/W:0 [4096, 512] 0.020831903\n",
      "fc2/W:0 [512, 10] 0.062204562\n",
      "Total params 2209472\n",
      "Epoch time 5.467350721359253\n",
      "Epoch 0 Train loss, accuracy 1.593530251420869 0.433688888888889\n",
      "EPoch 0 Validation loss, accuracy 1.6010676929473877 0.4338\n",
      "Epoch time 4.867661237716675\n",
      "Epoch 1 Train loss, accuracy 1.420520610666275 0.4948666666666666\n",
      "EPoch 1 Validation loss, accuracy 1.4246627110958099 0.497\n",
      "Epoch time 4.829834461212158\n",
      "Epoch 2 Train loss, accuracy 1.3040031701299883 0.5447333333333333\n",
      "EPoch 2 Validation loss, accuracy 1.3159491525173188 0.5456\n",
      "Epoch time 4.819650411605835\n",
      "Epoch 3 Train loss, accuracy 1.1806956511206101 0.5824222222222222\n",
      "EPoch 3 Validation loss, accuracy 1.2057365417480468 0.5706\n",
      "Epoch time 4.823241710662842\n",
      "Epoch 4 Train loss, accuracy 1.0988722954140768 0.6122444444444445\n",
      "EPoch 4 Validation loss, accuracy 1.1236781484127045 0.6102000000000001\n",
      "Epoch time 4.840301513671875\n",
      "Epoch 5 Train loss, accuracy 1.0388644402636422 0.6393333333333333\n",
      "EPoch 5 Validation loss, accuracy 1.0834552834510802 0.6276\n",
      "Epoch time 4.846012592315674\n",
      "Epoch 6 Train loss, accuracy 0.9972934802293777 0.654288888888889\n",
      "EPoch 6 Validation loss, accuracy 1.0468164812326433 0.6406\n",
      "Epoch time 4.853855133056641\n",
      "Epoch 7 Train loss, accuracy 0.923985436696476 0.6816444444444446\n",
      "EPoch 7 Validation loss, accuracy 0.9899570513248446 0.6652\n",
      "Epoch time 4.897213459014893\n",
      "Epoch 8 Train loss, accuracy 0.8674850260602105 0.7001555555555556\n",
      "EPoch 8 Validation loss, accuracy 0.9590437523126603 0.6686\n",
      "Epoch time 4.854115962982178\n",
      "Epoch 9 Train loss, accuracy 0.8371389554580053 0.7116\n",
      "EPoch 9 Validation loss, accuracy 0.9463049169063569 0.6796000000000001\n",
      "Epoch time 4.853765249252319\n",
      "Epoch 10 Train loss, accuracy 0.7650160400602553 0.7378222222222222\n",
      "EPoch 10 Validation loss, accuracy 0.8970129095077516 0.6947999999999999\n",
      "Epoch time 4.85460901260376\n",
      "Epoch 11 Train loss, accuracy 0.7165348043309318 0.7552000000000002\n",
      "EPoch 11 Validation loss, accuracy 0.8823694783687591 0.6990000000000001\n",
      "Epoch time 4.868281841278076\n",
      "Epoch 12 Train loss, accuracy 0.6888905441085498 0.7642666666666664\n",
      "EPoch 12 Validation loss, accuracy 0.8774836553573608 0.701\n",
      "Epoch time 4.9323344230651855\n",
      "Epoch 13 Train loss, accuracy 0.6469458506080839 0.7789111111111113\n",
      "EPoch 13 Validation loss, accuracy 0.8700924729108811 0.7066000000000001\n",
      "Epoch time 5.981373071670532\n",
      "Epoch 14 Train loss, accuracy 0.6585630467507574 0.7717777777777777\n",
      "EPoch 14 Validation loss, accuracy 0.9183639935255051 0.6933999999999999\n",
      "Epoch time 4.862562656402588\n",
      "Epoch 15 Train loss, accuracy 0.5542214574800598 0.8128444444444444\n",
      "EPoch 15 Validation loss, accuracy 0.8485844558715818 0.7182000000000001\n",
      "Epoch time 6.020530939102173\n",
      "Epoch 16 Train loss, accuracy 0.5473595677110884 0.8144222222222223\n",
      "EPoch 16 Validation loss, accuracy 0.8667966444730759 0.711\n",
      "Epoch time 4.931041955947876\n",
      "Epoch 17 Train loss, accuracy 0.4793901934279336 0.8426\n",
      "EPoch 17 Validation loss, accuracy 0.8442378669381142 0.7230000000000001\n",
      "Epoch time 4.8809120655059814\n",
      "Epoch 18 Train loss, accuracy 0.45551437091694935 0.8504222222222223\n",
      "EPoch 18 Validation loss, accuracy 0.8466703781247139 0.7232\n",
      "Epoch time 4.894994735717773\n",
      "Epoch 19 Train loss, accuracy 0.3935347437845336 0.8768444444444444\n",
      "EPoch 19 Validation loss, accuracy 0.8565319351673126 0.7295999999999999\n",
      "test accuracy 0.711\n",
      "Model saved in path: tmp/model\n"
     ]
    }
   ],
   "source": [
    "run_net(create_network_2,data_set=\"cifar\",draw=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run deeper network with same number of parameters on CIFAR10 images. Each conv layer has 3x3 filter "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1/W:0 [3, 3, 3, 32] 0.07869417\n",
      "conv1a/W:0 [3, 3, 32, 32] 0.05894272\n",
      "conv2/W:0 [3, 3, 32, 64] 0.048072267\n",
      "conv2a/W:0 [3, 3, 64, 64] 0.04167408\n",
      "fc1/W:0 [4096, 256] 0.021423034\n",
      "fc2/W:0 [256, 10] 0.088785596\n",
      "Total params 1116512\n",
      "Epoch time 5.736936807632446\n",
      "Epoch 0 Train loss, accuracy 1.649927035866843 0.40493333333333326\n",
      "EPoch 0 Validation loss, accuracy 1.6530010924816132 0.40259999999999996\n",
      "Epoch time 5.027634143829346\n",
      "Epoch 1 Train loss, accuracy 1.5247669275707667 0.4585333333333334\n",
      "EPoch 1 Validation loss, accuracy 1.5321210549831392 0.45380000000000004\n",
      "Epoch time 5.029931306838989\n",
      "Epoch 2 Train loss, accuracy 1.3771851545784208 0.5105111111111111\n",
      "EPoch 2 Validation loss, accuracy 1.392206236886978 0.5004\n",
      "Epoch time 5.033554315567017\n",
      "Epoch 3 Train loss, accuracy 1.2982385531160565 0.5383777777777777\n",
      "EPoch 3 Validation loss, accuracy 1.3140843524456025 0.5292\n",
      "Epoch time 5.038894891738892\n",
      "Epoch 4 Train loss, accuracy 1.2006401196135417 0.5807555555555556\n",
      "EPoch 4 Validation loss, accuracy 1.2256940973043442 0.5726\n",
      "Epoch time 5.047517538070679\n",
      "Epoch 5 Train loss, accuracy 1.1277879142310885 0.6043555555555553\n",
      "EPoch 5 Validation loss, accuracy 1.1637354821920396 0.5868\n",
      "Epoch time 5.049044847488403\n",
      "Epoch 6 Train loss, accuracy 1.049664114252726 0.6338666666666667\n",
      "EPoch 6 Validation loss, accuracy 1.097262013745308 0.6148\n",
      "Epoch time 5.046043872833252\n",
      "Epoch 7 Train loss, accuracy 0.9797554567813873 0.6599555555555557\n",
      "EPoch 7 Validation loss, accuracy 1.0533508277893067 0.6355999999999999\n",
      "Epoch time 5.047733306884766\n",
      "Epoch 8 Train loss, accuracy 0.9108896899461745 0.6840222222222221\n",
      "EPoch 8 Validation loss, accuracy 1.010567971777916 0.6544000000000001\n",
      "Epoch time 5.047030210494995\n",
      "Epoch 9 Train loss, accuracy 0.8580519984112843 0.7031111111111112\n",
      "EPoch 9 Validation loss, accuracy 0.9866021848917008 0.6643999999999999\n",
      "Epoch time 5.045303821563721\n",
      "Epoch 10 Train loss, accuracy 0.8024241450707117 0.7231111111111109\n",
      "EPoch 10 Validation loss, accuracy 0.9532078020572662 0.6738\n",
      "Epoch time 5.053080081939697\n",
      "Epoch 11 Train loss, accuracy 0.7653214035193125 0.7378444444444445\n",
      "EPoch 11 Validation loss, accuracy 0.9399004451274872 0.6759999999999999\n",
      "Epoch time 5.052045583724976\n",
      "Epoch 12 Train loss, accuracy 0.7350276408937243 0.7453555555555557\n",
      "EPoch 12 Validation loss, accuracy 0.9444458715200424 0.6815999999999999\n",
      "Epoch time 5.068766832351685\n",
      "Epoch 13 Train loss, accuracy 0.6772383521636328 0.7671111111111112\n",
      "EPoch 13 Validation loss, accuracy 0.9205432438373566 0.6936\n",
      "Epoch time 5.065047979354858\n",
      "Epoch 14 Train loss, accuracy 0.6609465021292368 0.7714222222222222\n",
      "EPoch 14 Validation loss, accuracy 0.9474300910711289 0.6854\n",
      "Epoch time 5.068442106246948\n",
      "Epoch 15 Train loss, accuracy 0.6400338297234642 0.779288888888889\n",
      "EPoch 15 Validation loss, accuracy 0.9762387705326081 0.6819999999999999\n",
      "Epoch time 5.097619533538818\n",
      "Epoch 16 Train loss, accuracy 0.5420565214342541 0.8171777777777779\n",
      "EPoch 16 Validation loss, accuracy 0.9263097334384918 0.6914\n",
      "Epoch time 5.1100921630859375\n",
      "Epoch 17 Train loss, accuracy 0.5137032200323212 0.8264444444444445\n",
      "EPoch 17 Validation loss, accuracy 0.9378513994932174 0.7005999999999999\n",
      "Epoch time 5.100404739379883\n",
      "Epoch 18 Train loss, accuracy 0.47012079096370274 0.8404222222222224\n",
      "EPoch 18 Validation loss, accuracy 0.9601602113127707 0.6914\n",
      "Epoch time 5.0722010135650635\n",
      "Epoch 19 Train loss, accuracy 0.41988224260807044 0.8586888888888888\n",
      "EPoch 19 Validation loss, accuracy 0.9900627830028533 0.6951999999999998\n",
      "test accuracy 0.6827\n",
      "Model saved in path: tmp/model\n"
     ]
    }
   ],
   "source": [
    "run_net(create_network_3,data_set=\"cifar\", draw=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
